#+TITLE: AWS Commands
#+SETUPFILE: ../../setup.org
#+PROPERTY: header-args+ :results output
#+PROPERTY: header-args+ :cache yes

* Variables                                                        :noexport:

  #+NAME: env
  | Env Var            | Value     |
  |--------------------+-----------|
  | AWS_PROFILE        | prod      |
  | AWS_DEFAULT_REGION | us-east-1 |

  #+begin_src emacs-lisp :var env=env
    (environ-set-pairs env)
  #+end_src

* Account

  Account number:

  #+name: Account
  #+begin_src sh
    aws sts get-caller-identity \
        --query 'Account' \
        --output text
  #+end_src

* IP Address Ranges

  AWS documentation is [[https://docs.aws.amazon.com/general/latest/gr/aws-ip-ranges.html][here]].

  #+NAME: IpRanges
  #+begin_src sh :results file :file ip_ranges.json
    curl -s https://ip-ranges.amazonaws.com/ip-ranges.json
  #+end_src

  #+RESULTS: IpRanges
  [[file:ip_ranges.json]]

  #+begin_src sh :var IpRanges=IpRanges
    cat "$IpRanges" \
        | jq '.prefixes[]
              | select(.region = "us-east-2")
              | .ip_prefix'
  #+end_src

** Get Region of IP

   (Would be cool).

   Check IP address against each CIDR range. Would be cool to do this using bit
   comparisons.

   See: https://unix.stackexchange.com/questions/274330/check-ip-is-in-range-of-whitelist-array

* Regions

** All regions in partition

   #+NAME: AllRegions
   #+begin_src sh
     aws ec2 describe-regions \
         | jq -r ".Regions[].RegionName"
   #+end_src

   #+RESULTS[04317e7a06778532f7f315cce532515421a80543]: AllRegions
   : eu-north-1
   : ap-south-1
   : eu-west-3
   : eu-west-2
   : eu-west-1
   : ap-northeast-3
   : ap-northeast-2
   : ap-northeast-1
   : sa-east-1
   : ca-central-1
   : ap-southeast-1
   : ap-southeast-2
   : eu-central-1
   : us-east-1
   : us-east-2
   : us-west-1
   : us-west-2

   Number of regions:

   #+begin_src sh :var AllRegions=AllRegions
     echo $AllRegions | wc -w   # Using wc

     regions=($AllRegions)      # Or use an array, and
     echo ${#regions[*]}        # print array length
   #+end_src

   #+RESULTS:
   : 21
   : 21

** All regions in all partitions

   Should be in the botocore data files. Also, we can pull them from the IpRanges
   document. You have to decide whether "GLOBAL" is a "region" in your situation.

   #+begin_src sh :var IpRanges=IpRanges
     cat "$IpRanges" \
         | jq -r '.prefixes[].region' \
         | sort | uniq
   #+end_src

** Run a command in all regions

*** Linear

    Get the number of VPCs in each region the slow and simple way.

    #+header: :var regions=AllRegions
    #+begin_src sh
      for region in $regions; do
          vpcs=($(aws --region $region ec2 describe-vpcs | jq '.Vpcs[].VpcId'))
          echo "$region: ${#vpcs[*]}"
      done
    #+end_src

    #+RESULTS:
    : eu-north-1: 0
    : ap-south-1: 0
    : eu-west-3: 0
    : eu-west-2: 0
    : eu-west-1: 0
    : ap-northeast-3: 1
    : ap-northeast-2: 0
    : ap-northeast-1: 0
    : sa-east-1: 0
    : ca-central-1: 0
    : ap-southeast-1: 1
    : ap-southeast-2: 0
    : eu-central-1: 0
    : us-east-1: 2
    : us-east-2: 3
    : us-west-1: 0
    : us-west-2: 0

*** Parallel

    Get the number of VPCs in each region the ðŸš€ and ðŸ˜Ž (and ðŸ¤®) way by starting
    a subprocess for each region in parallel. Note that =${#regions[@]}= is bash
    syntax for the length of the =$regions= array.

    #+header: :var regions=AllRegions
    #+begin_src sh
      script=$(cat <<-"EOF"
      vpcs=($(aws --region {} ec2 describe-vpcs | jq '.Vpcs[].VpcId'))
      echo "{}: ${#vpcs[@]}"
      EOF
      )

      regions=($regions)
      printf "%s\n" "${regions[@]}" \
          | xargs -n 1 \
                  -P ${#regions[*]} \
                  -I {} \
                  bash -c "$script"
    #+end_src

    #+RESULTS:
    : us-east-2: 8
    : ca-central-1: 2
    : eu-south-1: 1
    : eu-west-3: 1
    : us-west-2: 3
    : us-east-1: 97
    : eu-central-1: 1
    : us-west-1: 4
    : eu-north-1: 2
    : eu-west-2: 3
    : eu-west-1: 1
    : sa-east-1: 1
    : ap-northeast-2: 1
    : ap-northeast-1: 2
    : ap-south-1: 1
    : me-south-1: 1
    : ap-east-1: 1
    : ap-northeast-3: 1
    : af-south-1: 1
    : ap-southeast-1: 1
    : ap-southeast-2: 1

* ACM

** list-certificates

   #+begin_src sh
     aws acm list-certificates \
         --includes "keyUsage=ANY" \
         | jq '.CertificateSummaryList[]'
   #+end_src

** describe-certificate

   #+begin_src sh :var cert_arn=""
     aws acm describe-certificate \
         --certificate-arn $cert_arn
   #+end_src

** get-certificate

   #+begin_src sh :var cert_arn=""
     aws acm get-certificate \
         --certificate-arn $cert_arn
   #+end_src

** Get certificate PEM File

   #+begin_src sh :var cert_arn=""
     aws acm get-certificate \
         --certificate-arn $cert_arn \
         | jq -r '.Certificate' > cert.pem
   #+end_src

* API Gateway V2

** get-apis

   #+begin_src sh
     aws apigatewayv2 get-apis \
         | jq '.Items[]'
   #+end_src

* CloudFormation

  For create/deploy/update, see my [[https://github.com/cfclrk/cloudformation/blob/main/README.org][cloudformation/README.org]].

** View Stack Log

   #+begin_src sh
     aws cloudformation list-stacks \
         | jq -M '.StackSummaries[0].StackId' \
         | xargs aws cloudformation describe-stack-events --stack-name
   #+end_src

** List Stacks

   List only the created stacks

   #+begin_src sh
     aws cloudformation list-stacks \
         --stack-status-filter CREATE_IN_PROGRESS CREATE_COMPLETE
   #+end_src

** Stack Outputs

   #+begin_src sh :var StackName="test-network-public"
     aws cloudformation describe-stacks \
         --stack-name $StackName \
         | jq '.Stacks[].Outputs[]'
   #+end_src

   Get the value of a single output:

   #+begin_src sh :var StackName="test-network-public" OutputKey="PublicSubnet1"
     aws cloudformation describe-stacks \
         --stack-name $StackName \
         --query "Stacks[0].Outputs[?OutputKey=='$OutputKey'].OutputValue" \
         --output text
   #+end_src

** Get Stack Parameters

   Get all parameters used to create a particular stack:

   #+begin_src sh :var StackName="test-ec2-instance"
     aws cloudformation describe-stacks \
         --stack-name $StackName \
         | jq '.Stacks[].Parameters[]'
   #+end_src

   Get the value of a single parameter:

   #+begin_src sh :var StackName="test-ec2-instance" Parameter="DeploymentName"
     aws cloudformation describe-stacks \
         --stack-name $StackName \
         --query "Stacks[0].Parameters[?ParameterKey=='$Parameter'].ParameterValue" \
         --output text
   #+end_src

** Exports

   Get value of the exported field with name =$ExportName=:

   #+begin_src sh :var ExportName="test-PublicSubnet1"
     aws cloudformation list-exports \
         --query "Exports[?Name=='$ExportName'].Value" \
         --output text
   #+end_src

   List exports that start with a string:

   #+begin_src sh
     aws cloudformation list-exports \
         --query "Exports[?starts_with(Name, 'foo-')].[Name, Value]" \
         --output text
   #+end_src

** Spec Files

   URLs are documented [[https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-resource-specification.html][here]].

* CloudWatch

** Delete All Alarms

   #+begin_src sh
     alarms=$(aws cloudwatch describe-alarms \
                  | jq -r '.MetricAlarms[].AlarmName')

     for alarm in $alarms; do
         aws cloudwatch delete-alarms \
             --alarm-names $alarm;
     done
   #+end_src

** Create Alarm Targeting ASG policy

   #+begin_src sh
     aws cloudwatch put-metric-alarm \
         --alarm-name AddCapacity \
         --metric-name CPUUtilization \
         --namespace AWS/EC2 \
         --statistic Average \
         --period 120 \
         --threshold 80 \
         --comparison-operator GreaterThanOrEqualToThreshold \
         --dimensions "Name=AutoScalingGroupName,Value=my-asg" \
         --evaluation-periods 2 \
         --alarm-actions $ScalingPolicyArn
   #+end_src

* CodeDeploy

** list-deployments

   #+begin_src sh
     aws deploy list-deployments \
         --application-name $app
   #+end_src

** list-tags-for-resource

   #+begin_src sh
     aws deploy list-tags-for-resource \
         --resource-arn ""
   #+end_src

* DynamoDB

  The paper: [[https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf][Dynamo: Amazonâ€™s Highly Available Key-value Store]]. This describes a
  distributed database with a leaderless replication model.

  From [[https://shop.aer.io/oreilly/p/designing-data-intensive-applications/9781449373320-9149][Designing Data-Intensive Applications]] by Martin Kleppmann:

  #+begin_quote
  Dynamo is not available to users outside of Amazon. Confusingly, AWS offers a
  hosted database product called DynamoDB, which uses a completely different
  architecture: it is based on single-leader replication.
  #+end_quote

** List Tables

   #+begin_src sh
     aws dynamodb  list-tables | jq '.TableNames[]'
   #+end_src

** Delete Tables Like a Maniac

   AWS allows you to delete have 10 =delete-table= operations running at a time.
   We can create a pool of 10 processes and continuously pump =delete-table=
   commands into it using =xargs=.

   #+begin_src sh
     script=$(cat <<"EOF"
     aws dynamodb delete-table --table-name {}
     aws dynamodb wait table-not-exists --table-name {}
     EOF
           )
     echo ${tables[*]} \
         | xargs -n 1 -P 10 -I {} sh -c "$scrpt"
   #+end_src

   TODO: When I originally wrote this, I remember needing to add a =tr " " "\n"=
   or something for portability with Linux. Test this out again.

   TODO: script used to be one command (using =&&=); test again after splitting
   it into two commands.

* EC2 AMIs

** List AMIs

   All of this account's AMIs:

   #+begin_src sh :var Account=Account
     aws ec2 describe-images --owners $Account
   #+end_src

   All of this account's AMIs with a particular Name tag:

   #+begin_src sh
     aws ec2 describe-images \
         --owners $account \
         --filters "Name=tag:Name,Values=My AMI"
   #+end_src

** Get Latest Image

   #+begin_src sh :var Account=Account
     aws ec2 describe-images \
         --owners $Account \
         --filters "Name=state,Values=available" \
         | jq -r '.Images
                  | sort_by(.CreationDate)
                  | last | .ImageId'
   #+end_src

** Delete AMIs and EBS Snapshots

   List AMIs to delete and set to variable =AmisToDelete=. Then:

   #+begin_src sh :var AMIs=""
     jq -c '.Images
            | sort_by(.CreationDate)
            | .[]
            | {name: .Name, snap: .BlockDeviceMappings[]
            | select(.Ebs != null)
            | .Ebs.SnapshotId}' < $AmisToDelete > images.txt
   #+end_src

   And then... what did I do?

   #+begin_src sh
     for i in (cat images.txt | jq); do
         # deregister image
         # delete the snapshot
     done
   #+end_src

** List Accounts That Can Access AMI

   #+begin_src sh
     aws ec2 describe-image-attribute \
         --image-id $ImageID \
         --attribute launchPermission
   #+end_src

* EC2 AZs

  All AZs in all regions:

  #+header: :var AllRegions=AllRegions
  #+begin_src sh
    for region in $AllRegions; do
        azs=$(aws --region $region \
                  ec2 describe-availability-zones \
                  | jq -c '[.AvailabilityZones[].ZoneName]')
        printf "$region: $azs\n"
    done
  #+end_src

  #+RESULTS:
  : eu-north-1: ["eu-north-1a","eu-north-1b","eu-north-1c"]
  : ap-south-1: ["ap-south-1a","ap-south-1b","ap-south-1c"]
  : eu-west-3: ["eu-west-3a","eu-west-3b","eu-west-3c"]
  : eu-west-2: ["eu-west-2a","eu-west-2b","eu-west-2c"]
  : eu-west-1: ["eu-west-1a","eu-west-1b","eu-west-1c"]
  : ap-northeast-3: ["ap-northeast-3a","ap-northeast-3b","ap-northeast-3c"]
  : ap-northeast-2: ["ap-northeast-2a","ap-northeast-2b","ap-northeast-2c","ap-northeast-2d"]
  : ap-northeast-1: ["ap-northeast-1a","ap-northeast-1c","ap-northeast-1d"]
  : sa-east-1: ["sa-east-1a","sa-east-1b","sa-east-1c"]
  : ca-central-1: ["ca-central-1a","ca-central-1b","ca-central-1d"]
  : ap-southeast-1: ["ap-southeast-1a","ap-southeast-1b","ap-southeast-1c"]
  : ap-southeast-2: ["ap-southeast-2a","ap-southeast-2b","ap-southeast-2c"]
  : eu-central-1: ["eu-central-1a","eu-central-1b","eu-central-1c"]
  : us-east-1: ["us-east-1a","us-east-1b","us-east-1c","us-east-1d","us-east-1e","us-east-1f"]
  : us-east-2: ["us-east-2a","us-east-2b","us-east-2c"]
  : us-west-1: ["us-west-1b","us-west-1c"]
  : us-west-2: ["us-west-2a","us-west-2b","us-west-2c","us-west-2d"]

** The Actual AZ

   =us-east-1b= does not mean the same thing in every AWS account. If everyone
   creates infra in =us-east-1b=, that infra will actually be in several
   different AZs, depending on which AZ =us-east-1b= maps to for each account.
   To determine the /real/ AZ, you need to look at the *Zone ID*.

   Print the Zone Name and Zone ID for each AZ in a region:

   #+begin_src sh
     aws ec2 describe-availability-zones \
         | jq -c '.AvailabilityZones[]
                  | {"Name": .ZoneName, "Id": .ZoneId}'
   #+end_src

   #+RESULTS:
   : {"Name":"us-east-2a","Id":"use2-az1"}
   : {"Name":"us-east-2b","Id":"use2-az2"}
   : {"Name":"us-east-2c","Id":"use2-az3"}

* EC2 KeyPairs

** Create

   #+NAME: KeyPair
   #+header: :var KeyName="test"
   #+begin_src sh
     aws ec2 create-key-pair --key-name $KeyName
   #+end_src

   Copy private key to =~/.ssh=

   #+header: :var KeyPair=KeyPair dir="ironnet"
   #+begin_src bash
     KeyName=$(echo $KeyPair | jq -r '.KeyName')
     KeyFile=~/.ssh/$dir/$KeyName
     echo $KeyPair | jq -r '.KeyMaterial' > $KeyFile
     chmod 0600 $KeyFile
     echo $KeyFile
   #+end_src

** Describe

   #+begin_src sh
     aws ec2 describe-key-pairs | jq '.KeyPairs[]'
   #+end_src

** Delete

   #+begin_src sh :var KeyName="test"
     aws ec2 delete-key-pair --key-name $KeyName
   #+end_src

* EC2 Instances

** Get Running Instances

   #+begin_src sh
     aws ec2 describe-instances \
         --query "Reservations[].Instances[?State.name=="running"]"
   #+end_src

** Get All Instance Tags

   #+begin_src sh
     aws ec2 describe-instances \
         | jq -c '.Reservations[] | .Instances[] | .Tags[]'
   #+end_src

** Get Instances with Tag Key

   With just a specific Tag key, disregarding value:

   #+begin_src sh :var TagName=""
     aws ec2 describe-instances \
         --filter "Name=tag-key,Values=k8s.io/role/node" \
         | jq '.Reservations[].Instances[]'
   #+end_src

** Get Instances with Tag Key/Value

   With just a specific Tag key:

   #+header: :var TagName="Name" TagValue="nodes.zzh.cfc.ironk8s.net"
   #+begin_src sh
     aws ec2 describe-instances \
         --filter "Name=tag:$TagName,Values=$TagValue" \
         | jq -r '.Reservations[].Instances[].Tags[]
                  | select(.Key == "Name")
                  | .Value'
   #+end_src

   With a specific tag key and value

* EC2 Transit Gateway

** List Routes in a TG Route Table

   #+begin_src sh :results output :var TGWRouteTableId=""
     aws --profile shared-services --region us-east-1 \
         ec2 search-transit-gateway-routes \
         --transit-gateway-route-table-id $TGWRouteTableId \
         --filters "Name=type,Values=propagated" \
         | jq -r '.Routes[].DestinationCidrBlock'
   #+end_src

* EC2 VPCs

** VPCs

   #+begin_src bash
     aws ec2 describe-vpcs | jq '.Vpcs[]'
   #+end_src

   The names of VPCs that have a =Name= tag:

   #+begin_src sh
     aws ec2 describe-vpcs \
         --filters Name=tag-key,Values=Name \
         | jq -r '.Vpcs[].Tags[]
                  | select(.Key == "Name")
                  | .Value'
   #+end_src

** Subnets

   #+begin_src sh
     aws ec2 describe-subnets  | jq '.Subnets'
   #+end_src

** SecurityGroups

   #+begin_src sh
     aws ec2 describe-security-groups \
         | jq '.SecurityGroups'
   #+end_src

** Private ALB IPs

   #+begin_src sh
     aws ec2 describe-network-interfaces \
         | jq -r '.NetworkInterfaces[]
               | select(.Attachment.InstanceOwnerId == "amazon-elb")
               | .PrivateIpAddress'
   #+end_src

** Managed Prefix Lists

   #+begin_src sh
     aws ec2 describe-managed-prefix-lists \
         | jq '.PrefixLists[]'
   #+end_src

   #+header :var PrefixListID=""
   #+begin_src sh
     aws ec2 get-managed-prefix-list-entries \
         --prefix-list-id $PrefixListID \
         | jq '.Entries[]'
   #+end_src

* EC2 Volumes

** List Volumes

   #+NAME: AllVolumes
   #+header: :var Tag="kubernetes.io/cluster/steger1018test1"
   #+begin_src sh
     aws ec2 describe-volumes \
         --filters Name=tag-key,Values=$Tag \
         | jq -r '.Volumes[].VolumeId'
   #+end_src

** List Unattached Volumes

   #+NAME: UnattachedVolumes
   #+begin_src sh
     aws ec2 describe-volumes \
         --filters Name=status,Values=available \
         | jq -r '.Volumes[].VolumeId'
   #+end_src

** Delete Volumes

   #+header: :var Volumes=UnattachedVolumes
   #+begin_src sh
     for volume in $Volumes; do
         aws ec2 delete-volume --volume-id $volume
     done
   #+end_src

* ECR

** Log in

   TODO: =$account= doesn't work (newline)

   #+header: :var account=Account
   #+begin_src sh
     ecr=$account.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
     pw=$(aws ecr get-login-password)
     docker login \
            --username AWS \
            --password "$pw" \
            "https://$ecr"
   #+end_src

** Create Repository

   #+header: :var repoName="foo"
   #+begin_src sh
     aws ecr create-repository \
         --repository-name $repoName \
         --tags "Key=Foo,Value=True"
   #+end_src

** Add Image

   Tag image for ECR:

   #+header: :var image="k8s.gcr.io/sig-storage/livenessprobe"
   #+header: :var tag="v2.2.0"
   #+header: :var account=Account
   #+header: :var name="sig-storage-livenessprobe"
   #+begin_src sh
     ecr=$account.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
     docker tag \
            $image:$tag \
            $ecr/$name:$tag
   #+end_src

   Push it:

   #+header: :var tag="v2.2.0"
   #+header: :var account=Account
   #+begin_src sh
     ecr=$account.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
     docker push \
            $ecr/$name:$tag
   #+end_src

** describe-registry

   #+begin_src sh
     aws ecr describe-registry
   #+end_src

** describe-repositories

   #+begin_src sh
     aws ecr describe-repositories \
         --registry-id "<id>"
   #+end_src

** list-tags-for-resource

   The ARN is like =arn:aws:ecr:us-east-1:<account-num>:repository/<repo-name>=.

   #+header: :var arn=""
   #+begin_src sh
     aws ecr list-tags-for-resource \
         --resource-arn "$arn"
   #+end_src

* ECS

  Fix a CloudFormation deployment where an ECS service fails to stabilize. Taken
  from [[https://aws.amazon.com/premiumsupport/knowledge-center/cloudformation-ecs-service-stabilize/][this]] AWS blog post. Just updates the number of ECS service tasks to 0.

  #+header: :var cluster="my-cluster"
  #+header: :var service="my-service"
  #+begin_src sh
    aws ecs update-service \
        --cluster $cluster \
        --service $service \
        --desired-count 0
  #+end_src

** restart tasks

   #+begin_src sh
     aws ecs \
         update-service \
         --force-new-deployment \
         --service $service_name \
         --cluster $cluster_name
   #+end_src

** list-clusters

   #+begin_src sh
     aws ecs list-clusters \
         | jq '.clusterArns[]'
   #+end_src

** describe-clusters

   #+header: :var cluster="prod-zone-service-cluster"
   #+begin_src sh
     aws ecs describe-clusters \
         --clusters $cluster \
         | jq '.clusters[]'
   #+end_src

** describe-services

   #+header: :var cluster="prod-zone-service-cluster"
   #+header: :var service="service-prod"
   #+begin_src sh
     aws ecs describe-services \
         --cluster $cluster \
         --services $service \
         | jq '.services[]'
   #+end_src

** describe-task-definition

   #+header: :var task="sevice-prod:132"
   #+begin_src sh
     aws ecs describe-task-definition \
         --task-definition $task \
         | jq '.taskDefinition.containerDefinitions[]'
   #+end_src

** descibe-task-sets

   #+name: TaskSet
   #+header: :var cluster="prod-zone-service-cluster"
   #+header: :var service="service-prod"
   #+begin_src sh
     aws ecs describe-services \
         --cluster $cluster \
         --services $service \
         | jq -r '.services[].taskSets[].id'
   #+end_src

   #+header: :var cluster="prod-zone-service-cluster"
   #+header: :var service="service-prod"
   #+header: :var task_set=TaskSet
   #+begin_src sh
     aws ecs describe-task-sets \
         --cluster $cluster \
         --service $service \
         --task-sets $task_set \
         | jq '.taskSets[]'
   #+end_src

* EKS

** List Clusters

   #+begin_src sh
     aws eks list-clusters | jq '.clusters[]'
   #+end_src

** Get Kube Config

   #+begin_src sh :var CLUSTER_NAME="eks-ka"
     KUBECONFIG=~/.kube/ironnet_clusters/$CLUSTER_NAME
     aws eks update-kubeconfig \
         --name $CLUSTER_NAME \
         --kubeconfig $KUBECONFIG
   #+end_src

* Elasticache

** List CacheClusters

   #+begin_src sh
     aws elasticache describe-cache-clusters \
         --show-cache-node-info \
         | jq '.CacheClusters'
   #+end_src

** List ReplicationGroups

   #+begin_src sh
     aws elasticache describe-replication-groups
             | jq '.ReplicationGroups'
   #+end_src

* ElasticBeanstalk

** Config Options for Nampespace

   #+begin_src sh
     aws elasticbeanstalk describe-configuration-options \
         | jq '.Options[]
               | if .Namespace == "aws:autoscaling:launchconfiguration"
                 then .
                 else null
                 end'
   #+end_src

* ElasticLoadBalancingV2

** Describe ALBs

   #+begin_src sh
     aws elbv2 describe-load-balancers \
         | jq '.LoadBalancers[] | select(.Type == "application")'
   #+end_src

** Get DNS Name

   #+begin_src sh
     aws elbv2 describe-load-balancers \
         | jq -r --arg DEPLOYMENT_NAME "$DEPLOYMENT_NAME" \
              '.LoadBalancers[]
               | select(.Type == "application")
               | select(.LoadBalancerName
               | startswith($DEPLOYMENT_NAME))
               | .DNSName'
   #+end_src

* GlobalAccelerator

  GlobalAccelerator is only in =us-west-2=, so set the region explicitly.

** List Accelerators

   #+begin_src sh
     aws --region us-west-2 \
         globalaccelerator list-accelerators \
         | jq '.Accelerators[]'
   #+end_src

** List Listeners

   #+begin_src sh :var AcceleratorArn=""
     aws --region us-west-2 \
         globalaccelerator list-listeners \
         --accelerator-arn $AcceleratorArn
   #+end_src

** IPs

   #+begin_src sh
     aws --region us-west-2 \
         globalaccelerator list-accelerators \
         | jq -r '.Accelerators[].IpSets[].IpAddresses[]'
   #+end_src

* IAM

** Create Policy

   #+header: :var PolicyName="chris-clark-test"
   #+begin_src sh
     aws iam create-policy \
         --policy-name $PolicyName \
         --policy-document '{
       "Version": "2012-10-17",
       "Statement": [{
         "Effect": "Allow",
         "Action": [
           "secretsmanager:GetSecretValue",
           "secretsmanager:DescribeSecret"
         ],
         "Resource": [
           "arn:*:secretsmanager:*:*:secret:MySecret"
         ]
       }]
     }'
   #+end_src

** Describe Policy

   #+begin_src sh
     aws iam get-policy --policy-arn $arn
   #+end_src

** Assume Role

   #+NAME: RoleCreds
   #+begin_src sh
     aws sts assume-role \
         --role-session-name foo \
         --role-arn $RoleArn
   #+end_src

** List Instance Profiles

   #+begin_src sh
     aws iam list-instance-profiles \
         | jq '.InstanceProfiles[].InstanceProfileName'
   #+end_src

** Delete Instance Profile

   #+begin_src sh :var Name=""
     aws iam delete-instance-profile \
         --instance-profile-name $Name
   #+end_src

* IMDS

  http://169.254.169.254/latest/meta-data/

* Kinesis

** Delete Stream

   #+begin_src sh
     aws kinesis delete-stream --stream-name $stream
   #+end_src

* Kinesis Firehose

** Describe Stream

   #+begin_src sh :var StreamName=""
     aws firehose describe-delivery-stream \
         --delivery-stream-name $StreamName \
         | jq '.DeliveryStreamDescription'
   #+end_src

** Update Stream S3 Destination Bucket

   #+begin_src sh :var StreamName="" BucketName="example"
     aws firehose update-destination \
         --delivery-stream-name $StreamName \
         --current-delivery-stream-version-id 1 \
         --destination-id destinationId-000000000001 \
         --extended-s3-destination-update \
         BucketARN=arn:aws:s3:::$BucketName
   #+end_src

   THEN:

   - Update the Stream's IAM policy to allow it to write to the new location
   - Update the S3 Bucket Policy to allow the Stream's IAM Role to write to it

** Update Stream S3 Destination Prefix

   #+begin_src sh :var StreamName="" Prefix="firehose/example/"
     aws firehose update-destination \
         --delivery-stream-name $StreamName \
         --current-delivery-stream-version-id 1 \
         --destination-id destinationId-000000000001 \
         --extended-s3-destination-update Prefix=$Prefix
   #+end_src

   Also may need to update the IAM Policy and the S3 Bucket policy, as above.

* Lambda

** Invoke function

   #+begin_src bash
     aws lambda invoke \
         --cli-binary-format raw-in-base64-out \
         --function-name cf-Hello-World \
         /tmp/cats.json
   #+end_src

   Invoke from a bastion host:

   #+header: :dir /ssh:ec2-user@13.59.90.58|ssh:ec2-user@10.192.20.15:/
   #+begin_src bash :results output
     /usr/local/bin/aws lambda invoke \
                        --cli-binary-format raw-in-base64-out \
                        --function-name cf-Hello-World \
                        /tmp/cats.json
   #+end_src

   #+begin_src sh
     cat /tmp/out.json | jq -r '.body' | jq
   #+end_src

   With payload file:

   #+begin_src bash
     aws lambda invoke \
         --cli-binary-format raw-in-base64-out \
         --function-name hello-world \
         --payload file://tests/resources/event_alb.json \
         /tmp/out.json
   #+end_src

** Create Function with Zip File

   #+begin_src sh
     aws lambda create-function \
         --function-name artifacttool \
         --runtime python2.7 \
         --role $RoleArn \
         --handler lambda_function.lambda_handler \
         --zip-file fileb://$ZipFileName
   #+end_src

** Update Function code with Zip File

   #+begin_src sh
     aws lambda update-function-code \
         --function-name artifacttool \
         --zip-file fileb://$ZipFileName
   #+end_src

** Container Image: Run Interactively

   #+begin_src sh
     docker run -it --rm \
            --entrypoint bash \
            public.ecr.aws/lambda/python:3.8
   #+end_src

* Organizations

  #+NAME: OrgRoot
  #+begin_src sh
    aws organizations list-roots \
        | jq -r '.Roots[].Id'
  #+end_src

* Polly

  #+begin_src sh
    aws polly synthesize-speech \
        --engine standard \
        --output-format mp3 \
        --voice-id Amy \
        --text "All these cats wear hats." \
        /tmp/speech_standard.mp3 \
        && afplay /tmp/speech_standard.mp3
  #+end_src

* Reosurce Access Manager (RAM)

  This needs to be run against the AWS account that actually owns the shared
  resources. E.g. in a LandingZone environment, probably the shared-services
  account.

  #+begin_src sh
    aws ram list-resources --resource-owner SELF
  #+end_src

* RDS

** describe-db-instances

   #+header: :var db_name="foo-dev"
   #+begin_src sh
     aws rds describe-db-instances \
         --db-instance-identifier "$db_name" \
         | jq '.DBInstances[]'
   #+end_src

** modify-db-instance

   Run this command to apply pending maintenance:

   #+header: :var db_name="foo-dev"
   #+begin_src sh
     aws rds modify-db-instance \
         --db-instance-identifier "$db_name" \
         --apply-immediately
   #+end_src

** describe-db-engine-versions

   #+begin_src sh
     aws rds describe-db-engine-versions \
         --engine "postgres" \
         --filters 'Key=status,Values=deprecated'
   #+end_src

** pending maintenance actions for a DB

   #+begin_src sh
     aws rds describe-pending-maintenance-actions \
         | jq '.PendingMaintenanceActions[]
               | select(.ResourceIdentifier=="$DB_ARN")'
   #+end_src

** create-db-snapshot

   #+header: :var snap_id="my-snap-name"
   #+begin_src sh
     aws rds create-db-snapshot \
         --db-snapshot-identifier "$snap_id" \
         --db-instance-identifier work-number-dev
   #+end_src

   Check whether a snapshot exists yet:

   #+header: :var snap_id="my-snap-name"
   #+header: :var db_name="foo-dev"
   #+begin_src sh
     aws rds describe-db-snapshots \
         --db-snapshot-identifier "$snap_id" \
         --db-instance-identifier "$db_name" \
         | jq '.DBSnapshots[].OriginalSnapshotCreateTime'
   #+end_src

** create-parameter-group

   #+begin_src sh
     aws rds create-db-parameter-group \
         --db-parameter-group-name "cclark-test" \
         --db-parameter-group-family "postgres11" \
         --description "cclark test group"
   #+end_src

   #+begin_src sh
     aws rds modify-db-parameter-group \
         --db-parameter-group-name "cclark-test" \
         --parameters "ParameterName='max_slot_wal_keep_size',ParameterValue=4000,ApplyMethod=immediate"
   #+end_src

** describe-parameter-group

   #+begin_src sh
     aws rds describe-db-parameters \
         --db-parameter-group-name "cclark-test" \
         | jq '.Parameters[]
               | select(.ParameterName | contains("wal_"))'
   #+end_src

* Route53

** Get HostedZoneId from domain name

   #+NAME: HostedZoneId
   #+header: :var hostedZoneName="irondev.io"
   #+begin_src sh
     aws route53 list-hosted-zones \
         | jq -r --arg name $hostedZoneName \
              '.HostedZones[]
               | select(.Name == $name + ".")
               | select(.Config.PrivateZone == false)
               | .Id'
   #+end_src

** List Records for a HostedZone

   #+header: :var hostedZoneId=HostedZoneId
   #+begin_src sh
     aws route53 list-resource-record-sets \
         --hosted-zone-id $hostedZoneId \
         | jq '.ResourceRecordSets[]'
   #+end_src

* SageMaker

** list-models

  #+begin_src sh
    aws sagemaker list-models | jq '.Models[]'
  #+end_src

* SecretsManager

** List Secrets

   #+begin_src sh
     aws secretsmanager list-secrets \
         | jq -r '.SecretList[].Name'
   #+end_src

   Filter:

   #+begin_src sh
     aws secretsmanager list-secrets \
         --filters 'Key=name,Values=foo/bar' \
         | jq -r '.SecretList[].Name'
   #+end_src

** Get Secret

   #+header: :var SecretName="/ixiactl/BP_PASSWORD"
   #+begin_src sh
     aws secretsmanager get-secret-value \
         --secret-id $SecretName \
         | jq -r '.SecretString'
   #+end_src

** Create Secret

   #+begin_src sh :var SecretName="/ixiactl/BP_PASSWORD" SecretValue=""
     aws secretsmanager create-secret \
         --name $SecretName \
         --secret-string $SecretValue
   #+end_src

* ServiceCatalog

** Get Product IDs

   #+begin_src sh
     aws --profile main servicecatalog search-products-as-admin
   #+end_src

** Launch Product

   Note that user, even Admin user, must be added to the Portfolio users/groups.
   You can do this with =aws servicecatalog associate-principal-with-portfolio=

* Service Quotas

** Get all service quotas

   #+begin_src sh :results output
     aws service-quotas list-service-quotas \
         --service-code rds \
         | jq -c '.Quotas[] | {Value, QuotaName}'
   #+end_src

** Get one quota

   #+begin_src sh
     aws service-quotas list-service-quotas \
         --service-code rds \
         | jq '.Quotas[]
               | select(.QuotaName == "Parameter groups")'
   #+end_src

** Get default quota

   Is this actually different from the above? What makes this default?

   #+begin_src sh
     aws service-quotas get-aws-default-service-quota \
         --service-code firehose \
         --quota-code "L-14BB0BE7" \
         | jq '.Quota'
   #+end_src

* S3

** Canonical ID

   #+begin_src sh :var BucketName=""
     aws s3api get-bucket-acl --bucket $BucketName
   #+end_src

** list-buckets

   List buckets that start with the name =$prefix=.

   #+header: :var prefix="foo"
   #+begin_src sh
     aws s3api list-buckets \
         | jq -r --arg prefix $prefix \
              '.Buckets[]
               | select(.Name | startswith($prefix)).Name'
   #+end_src

** Create Bucket

   #+header: :var BUCKET_NAME="cfc-s3"
   #+begin_src sh
     aws s3api create-bucket \
         --bucket $BUCKET_NAME \
         --create-bucket-configuration LocationConstraint=$AWS_DEFAULT_REGION
   #+end_src

** List Objects

   All objects

   #+begin_src sh :var BucketName=""
     aws s3api list-objects-v2 \
         --bucket $BucketName \
         | jq '.Contents[]'
   #+end_src

   10 most recent objects. AWS has no way of doing this filtering server-side,
   so you need to request all objects and then sort them.

   #+begin_src sh :var BucketName="" :results output
     aws s3api list-objects-v2 \
         --bucket $BucketName \
         | jq -r '.Contents
                  | sort_by(.LastModified)
                  | reverse | first | .Key'
   #+end_src

** Get object

   #+header: :var BucketName="" Key=""
   #+begin_src sh
     aws s3api get-object \
         --bucket $BucketName \
         --key $Key ./foo
   #+end_src

** Get multiple objects

   #+header: :var BucketName=""
   #+begin_src sh
     mkdir -p ~/Downloads/foo
     aws s3 cp \
         --recursive \
         s3://$BucketName/ \
         ~/Downloads/foo/
   #+end_src

** Get Bucket Policy

   #+begin_src sh :var BucketName="" :results output
     aws s3api get-bucket-policy --bucket $BucketName \
         | jq -r '.Policy' | jq
   #+end_src

** Clear and delete buckets

   To clear a bucket, I have functions for this in [[https://github.com/cfclrk/dotfiles/blob/master/dotfiles/.functions.fish][dotfiles/.functions.fish]].

* SNS

** SNS topics

   #+begin_src sh
     aws sns list-topics \
         | jq '.Topics[] | .TopicArn'
   #+end_src

* SQS

** List Queues

   #+begin_src sh
     aws sqs list-queues \
         | jq '.QueueUrls[]'
   #+end_src

** Read Message

   #+name: ReadMessage
   #+header: :var q_url="https://sqs.us-east-1.amazonaws.com/..."
   #+begin_src sh
     aws sqs receive-message \
         --queue-url "$q_url" \
         --attribute-names All \
         --message-attribute-names All \
         --max-number-of-messages 2
   #+end_src

** Send Message

   #+header: :var q_url=""
   #+begin_src sh
     aws sqs send-message \
         --queue-url "$q_url" \
         --message-body '{"Message": "{\"foo\":\"bar\"}"}'
   #+end_src

* SSM

  #+header: :var name="/aws/service/eks/optimized-ami/1.19/amazon-linux-2/recommended/image_id"
  #+begin_src sh
    aws ssm get-parameter \
        --with-decryption \
        --name $name
  #+end_src

* Identity Store (SSO)

  AWS SSO was renamed to AWS Identity Store.

  - [[https://docs.aws.amazon.com/singlesignon/latest/IdentityStoreAPIReference/welcome.html][Identity Store API Reference]]

    These API operations correspond to the =aws identitystore= commands.

  - [[https://docs.aws.amazon.com/singlesignon/latest/PortalAPIReference/Welcome.html][IAM Idenetity Center Portal API Reference]]

    These API operations correspond to the =aws sso= commands.

** Register client

   This command *does not* require AWS credentials. You only need a region.

   #+begin_src sh
     aws --region us-east-1 sso-oidc register-client \
         --client-name foo \
         --client-type public
   #+end_src

   Returns an object like:

   #+begin_example
     {
         "clientId": "abc1234",
         "clientSecret": "a JSON Web Token",
         "clientIdIssuedAt": 1659099242,
         "clientSecretExpiresAt": 1666875242
     }
   #+end_example

** Token

   #+begin_src sh
     aws sso login
   #+end_src

   #+NAME: SsoToken
   #+headers: :var token_name=""
   #+begin_src sh
     token_file=~/.aws/sso/cache/$token_name.json
     cat $token_file | jq -r '.accessToken'
   #+end_src

** List my accounts

   #+header: :var token=SsoToken
   #+begin_src sh :results output
     aws --region us-east-1 sso list-accounts \
         --access-token $token
   #+end_src

   #+header: :var account=123456789
   #+header: :var token=SsoToken
   #+begin_src sh
     aws --region us-east-1 sso list-account-roles \
         --access-token $token \
         --account-id $account
   #+end_src

** Get credentials

   The jq can be improved. See: https://github.com/aws/aws-cli/issues/5261

   #+header: :var account=123456789
   #+header: :var token=SsoToken
   #+header: :var role="tribe_sso_permission_set"
   #+begin_src sh :results file :file ~/.env/aws_creds
     creds=$(aws --region us-east-1 sso get-role-credentials \
                 --role-name $role \
                 --account-id $account \
                 --access-token $token)

     access_key=$(echo $creds | jq '.roleCredentials.accessKeyId')
     secret_key=$(echo $creds | jq '.roleCredentials.secretAccessKey')
     access_token=$(echo $creds | jq '.roleCredentials.sessionToken')

     echo "AWS_ACCESS_KEY_ID=$access_key"
     echo "AWS_SECRET_ACCESS_KEY=$secret_key"
     echo "AWS_SESSION_TOKEN=$access_token"
     echo "AWS_REGION=us-east-1"
     echo "AWS_DEFAULT_REGION=us-east-1"
   #+end_src
